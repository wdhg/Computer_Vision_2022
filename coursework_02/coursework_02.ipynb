{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 2: Fish Classification\n",
    "\n",
    "Created by Athanasios Vlontzos and Wenjia Bai\n",
    "\n",
    "In this coursework, you will be exploring the application of convolutional neural networks for image classification tasks. As opposed to standard applications such as object or face classification, we will be dealing with a slightly different domain, fish classification for precision fishing.\n",
    "\n",
    "In precision fishing, engineers and fishmen collaborate to extract a wide variety of information about the fish, their species and wellbeing etc. using data from satellite images to drones surveying the fisheries. The goal of precision fishing is to provide the marine industry with information to support their decision making processes.\n",
    "\n",
    "Here your will develop an image classification model that can classify fish species given input images. It consists of two tasks. The first task is to train a model for the following species:\n",
    "- Black Sea Sprat\n",
    "- Gilt-Head Bream\n",
    "- Shrimp\n",
    "- Striped Red Mullet\n",
    "- Trout\n",
    "\n",
    "The second task is to finetune the last layer of the trained model to adapt to some new species, including:\n",
    "- Hourse Mackerel\n",
    "- Red Mullet\n",
    "- Red Sea Bream\n",
    "- Sea Bass\n",
    "\n",
    "You will be working using a large-scale fish dataset [1].\n",
    "\n",
    "[1] O. Ulucan, D. Karakaya and M. Turkan. A large-scale dataset for fish segmentation and classification. Innovations in Intelligent Systems and Applications Conference (ASYU). 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Download data.\n",
    "\n",
    "[Download the Data from here -- make sure you access it with your Imperial account.](https://imperiallondon-my.sharepoint.com/:f:/g/personal/av2514_ic_ac_uk/EkA9HyXVvgdFoLI4P_IfO1cBO_CsvY1KN4NE8iuD-s_VlA?e=Ip03rF)\n",
    "\n",
    "It is a ~2.5GB file. You can save the images and annotations directories in the same directory as this notebook or somewhere else.\n",
    "\n",
    "The fish dataset contains 9 species of fishes. There are 1,000 images for each fish species, named as %05d.png in each subdirectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data. (15 Points)\n",
    "\n",
    "- Complete the dataset class with the skeleton below.\n",
    "- Add any transforms you feel are necessary.\n",
    "\n",
    "Your class should have at least 3 elements\n",
    "- An ```__init__``` function that sets up your class and all the necessary parameters.\n",
    "- An ```__len__``` function that returns the size of your dataset.\n",
    "- An ```__getitem__``` function that given an index within the limits of the size of the dataset returns the associated image and label in tensor form.\n",
    "\n",
    "You may add more helper functions if you want.\n",
    "\n",
    "In this section we are following the Pytorch [dataset](https://pytorch.org/vision/stable/datasets.html) class structure. You can take inspiration from their documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We will start by building a dataset class using the following 5 species of fishes\n",
    "Multiclass_labels_correspondances = {\n",
    "    'Black Sea Sprat': 0,\n",
    "    'Gilt-Head Bream': 1,\n",
    "    'Shrimp': 2,\n",
    "    'Striped Red Mullet': 3,\n",
    "    'Trout': 4\n",
    "}\n",
    "\n",
    "# The 5 species will contain 5,000 images in total.\n",
    "# Let us split the 5,000 images into training (80%) and test (20%) sets\n",
    "SPECIES_DATASET_SIZE = 1000\n",
    "\n",
    "# assuming even split across all classes\n",
    "def split_train_test(lendata, num_classes, percentage=0.8):\n",
    "    images_per_class = int(lendata / num_classes)\n",
    "    training_images_per_class = int(images_per_class * percentage)\n",
    "    testing_images_count_per_class = images_per_class - training_images_per_class\n",
    "    \n",
    "    idx = 0\n",
    "    idxs_train = []\n",
    "    idxs_test = []\n",
    "        \n",
    "    for _ in range(int(num_classes)):\n",
    "        idxs_train.extend(range(idx, idx + training_images_per_class))\n",
    "        idx += training_images_per_class\n",
    "        idxs_test.extend(range(idx, idx + testing_images_count_per_class))\n",
    "        idx += testing_images_count_per_class\n",
    "        \n",
    "    return idxs_train, idxs_test\n",
    "\n",
    "LENDATA = 5000\n",
    "np.random.seed(42)\n",
    "idxs_train, idxs_test = split_train_test(LENDATA, len(Multiclass_labels_correspondances), 0.8)\n",
    "\n",
    "class DatasetImage():\n",
    "    \n",
    "    def __init__(self,\n",
    "                image,\n",
    "                label):\n",
    "        self.image = image\n",
    "        self.label = label\n",
    "    \n",
    "# Implement the dataset class\n",
    "class FishDataset(ImageFolder):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 path_to_images,\n",
    "                 idxs_train,\n",
    "                 idxs_test,\n",
    "                 transform_extra=None,\n",
    "                 img_size=128,\n",
    "                 train=True):\n",
    "        super().__init__(path_to_images)\n",
    "        # path_to_images: where you put the fish dataset\n",
    "        # idxs_train: training set indexes\n",
    "        # idxs_test: test set indexes\n",
    "        # transform_extra: extra data transform\n",
    "        # img_size: resize all images to a standard size\n",
    "        # train: return training set or test set\n",
    "        \n",
    "        self.idxs = idxs_train if train else idxs_test\n",
    "        self.size = len(self.idxs)\n",
    "        self.images = []\n",
    "        self.class_idxs = {}\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        class_files = {}\n",
    "        \n",
    "        # get filenames\n",
    "        for label in Multiclass_labels_correspondances:\n",
    "            class_files[label] = sorted(glob.glob(f'{path_to_images}/{label}/*.png'))\n",
    "        \n",
    "        idx = 0\n",
    "        \n",
    "        for label in class_files.keys():\n",
    "            self.class_idxs[label] = []\n",
    "            \n",
    "            for file in class_files[label]:\n",
    "                if idx not in self.idxs:\n",
    "                    idx += 1\n",
    "                    continue\n",
    "                    \n",
    "                image = Image.open(file)\n",
    "                image = transform(image)\n",
    "                self.images.append(DatasetImage(image, label))\n",
    "                self.class_idxs[label].append(len(self.images) - 1)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        dataset_image = self.images[idx]\n",
    "        return dataset_image.image, Multiclass_labels_correspondances[dataset_image.label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Explore the data. (15 Points)\n",
    "\n",
    "### Step 2.1: Data visualisation. (5 points)\n",
    "\n",
    "- Plot data distribution, i.e. the number of samples per class.\n",
    "- Plot 1 sample from each of the five classes in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Training set\n",
    "img_path = './archive/Fish_Dataset/Fish_Dataset'\n",
    "dataset  = FishDataset(img_path, idxs_train, idxs_test, None, img_size=128, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of samples per class\n",
    "classes = list(Multiclass_labels_correspondances.keys())\n",
    "counts = [len(dataset.class_idxs[c]) for c in classes]\n",
    "\n",
    "plt.bar(classes, counts)\n",
    "plt.xticks(range(len(classes)), classes, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1 sample from each of the five classes in the training set\n",
    "figure, axis = plt.subplots(1, 5)\n",
    "\n",
    "for i, c in enumerate(classes):\n",
    "    idx = np.random.choice(dataset.class_idxs[c])\n",
    "    image, label = dataset[idx]\n",
    "    image = np.transpose(image.detach().numpy(), (1,2,0))\n",
    "    axis[i].imshow(image)\n",
    "    \n",
    "plt.gcf().set_size_inches(15, 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Discussion. (10 points)\n",
    "\n",
    "* Is the dataset balanced?\n",
    "\n",
    "* Can you think of 3 ways to make the dataset balanced if it is not?\n",
    "\n",
    "* Is the dataset already pre-processed? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is balanced as there is an equal number of images per class.\n",
    "\n",
    "The dataset is not pre-processed. The fish are not centred, rotated the same direction, or normalised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Multiclass classification. (55 points)\n",
    "In this section we will try to make a multiclass classifier to determine the species of the fish.\n",
    "\n",
    "### Step 3.1: Define the model. (15 points)\n",
    "\n",
    "Design a neural network which consists of a number of convolutional layers and a few fully connected ones at the end.\n",
    "\n",
    "The exact architecture is up to you but you do NOT need to create something complicated. For example, you could design a LeNet insprired network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, output_dims = 1):\n",
    "        super(Net, self).__init__()\n",
    "        # 3x128x128\n",
    "        # self.add_module(\"conv1\", torch.nn.Conv2d(3, 1, (5,5), padding=2))\n",
    "        # 1x128x128\n",
    "        # self.add_module(\"sigmoid1\", torch.nn.Sigmoid())\n",
    "        # 1x128x128\n",
    "        # self.add_module(\"pool1\", torch.nn.AvgPool2d(2, stride=2))\n",
    "        # 1x64x64\n",
    "        # self.add_module(\"conv2\", torch.nn.Conv2d(1, 1, (5,5)))\n",
    "        # 1x60x60\n",
    "        # self.add_module(\"sigmoid2\", torch.nn.Sigmoid())\n",
    "        # 1x60x60\n",
    "        # elf.add_module(\"pool2\", torch.nn.AvgPool2d(2, stride=2))\n",
    "        # 1x30x30\n",
    "        # self.add_module(\"flatten\", torch.nn.Flatten())\n",
    "        # 60\n",
    "        # self.add_module(\"linear1\", torch.nn.Linear(60, 30))\n",
    "        # 30\n",
    "        # self.add_module(\"linear2\", torch.nn.Linear(30, 10))\n",
    "        # 10\n",
    "        # self.add_module(\"linear3\", torch.nn.Linear(10, output_dims))\n",
    "        \n",
    "        # 3x128x128\n",
    "        self.add_module(\"conv1\", torch.nn.Conv2d(3, 1, (5,5), padding=2))\n",
    "        # 1x128x128\n",
    "        # self.add_module(\"sigmoid1\", torch.nn.Sigmoid())\n",
    "        self.add_module(\"pool1\", torch.nn.AvgPool2d(2, stride=2))\n",
    "        # 1x64x64\n",
    "        self.add_module(\"conv2\", torch.nn.Conv2d(1, 1, (5,5), padding=2))\n",
    "        # 1x64x64\n",
    "        # self.add_module(\"sigmoid2\", torch.nn.Sigmoid())\n",
    "        self.add_module(\"pool2\", torch.nn.AvgPool2d(2, stride=2))\n",
    "        # 1x32x32\n",
    "        self.add_module(\"conv3\", torch.nn.Conv2d(1, 1, (3,3), padding=1))\n",
    "        # 1x32x32\n",
    "        self.add_module(\"sigmoid3\", torch.nn.Sigmoid())\n",
    "        self.add_module(\"pool3\", torch.nn.AvgPool2d(2, stride=2))\n",
    "        # 1x16x16\n",
    "        self.add_module(\"flatten\", torch.nn.Flatten())\n",
    "        # 1x256\n",
    "        self.add_module(\"linear1\", torch.nn.Linear(256, 64))\n",
    "        self.add_module(\"linear2\", torch.nn.Linear(64, 16))\n",
    "        self.add_module(\"linear3\", torch.nn.Linear(16, output_dims))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.children():\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# Since most of you use laptops, you may use CPU for training.\n",
    "# If you have a good GPU, you can set this to 'gpu'.\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Define the training parameters. (10 points)\n",
    "\n",
    "- Loss function\n",
    "- Optimizer\n",
    "- Learning Rate\n",
    "- Number of iterations\n",
    "- Batch Size\n",
    "- Other relevant hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Network\n",
    "model = Net(output_dims=5) # one-hot output vector\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.L1Loss()\n",
    "\n",
    "# Optimiser and learning rate\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.5)\n",
    "\n",
    "# Number of iterations for training\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training dataset...\n",
      "Loading testing dataset...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Training batch size\n",
    "train_batch_size = 400\n",
    "\n",
    "# Based on the FishDataset, use the PyTorch DataLoader to load the data during model training\n",
    "print(\"Loading training dataset...\")\n",
    "train_dataset = FishDataset(img_path, idxs_train, idxs_test, None, img_size=128, train=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "print(\"Loading testing dataset...\")\n",
    "test_dataset = FishDataset(img_path, idxs_train, idxs_test, None, img_size=128, train=False)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3: Train the model. (15 points)\n",
    "\n",
    "Complete the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█████████▌                                                                                     | 1/10 [00:09<01:27,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 1: training loss = 0.2847 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████████████                                                                            | 2/10 [00:18<01:13,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 2: training loss = 0.2138 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████████▌                                                                  | 3/10 [00:27<01:02,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 3: training loss = 0.2092 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████████████                                                         | 4/10 [00:36<00:54,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 4: training loss = 0.2091 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████▌                                               | 5/10 [00:45<00:44,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 5: training loss = 0.2079 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████████████                                      | 6/10 [00:53<00:34,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 6: training loss = 0.2073 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████████████▌                            | 7/10 [01:02<00:26,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 7: training loss = 0.2068 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████                   | 8/10 [01:11<00:17,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 8: training loss = 0.2074 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████▌         | 9/10 [01:20<00:08,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 9: training loss = 0.2086 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [01:29<00:00,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iteration 10: training loss = 0.2093 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "full_loss_curve = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    loss_curve = []\n",
    "    \n",
    "    for images, labels in train_dataloader:\n",
    "        # Get a batch of training data and train the model\n",
    "        pred = model(images)\n",
    "        loss = criterion(pred, torch.nn.functional.one_hot(labels, num_classes=5))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_curve += [loss.item()]\n",
    "\n",
    "    full_loss_curve.extend(loss_curve)\n",
    "        \n",
    "    print('--- Iteration {0}: training loss = {1:.4f} ---'.format(epoch + 1, np.array(loss_curve).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(full_loss_curve)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.4: Deploy the trained model onto the test set. (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Deploy the model\n",
    "model.train(mode=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.5: Evaluate the performance of the model and visualize the confusion matrix. (5 points)\n",
    "\n",
    "You can use sklearns related function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### ADD YOUR CODE HERE ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Finetune your classifier. (15 points)\n",
    "\n",
    "In the previous section, you have built a pretty good classifier for certain species of fish. Now we are going to use this trained classifier and adapt it to classify a new set of species:\n",
    "\n",
    "    'Hourse Mackerel\n",
    "    'Red Mullet',\n",
    "    'Red Sea Bream'\n",
    "    'Sea Bass'\n",
    "\n",
    "### Step 4.1: Set up the data for new species. (2 points)\n",
    "Overwrite the labels correspondances so they only incude the new classes and regenerate the datasets and dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Multiclass_labels_correspondances ={\n",
    "    'Hourse Mackerel': 0,\n",
    "    'Red Mullet': 1,\n",
    "    'Red Sea Bream': 2,\n",
    "    'Sea Bass': 3}\n",
    "\n",
    "LENDATA = 4000\n",
    "idxs_train,idxs_test = split_train_test(LENDATA, 0.8)\n",
    "\n",
    "# Dataloaders\n",
    "#### ADD YOUR CODE HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2: Freeze the weights of all previous layers of the network except the last layer. (5 points)\n",
    "\n",
    "You can freeze them by setting the gradient requirements to ```False```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def freeze_till_last(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "freeze_till_last(model)\n",
    "# Modify the last layer. This layer is not freezed.\n",
    "#### ADD YOUR CODE HERE ####\n",
    "\n",
    "# Loss function\n",
    "criterion =\n",
    "\n",
    "# Optimiser and learning rate\n",
    "lr =\n",
    "optimizer =\n",
    "\n",
    "# Number of iterations for training\n",
    "epochs =\n",
    "\n",
    "# Training batch size\n",
    "train_batch_size ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.3: Train and test your finetuned model. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Finetune the model\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    #### ADD YOUR CODE HERE ####\n",
    "\n",
    "# Deploy the model on the test set\n",
    "#### ADD YOUR CODE HERE ####\n",
    "\n",
    "# Evaluate the performance\n",
    "#### ADD YOUR CODE HERE ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.4: Did finetuning work? Why did we freeze the first few layers? (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADD YOUR RESPONSE HERE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
